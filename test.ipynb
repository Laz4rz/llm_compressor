{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 1311 bytes\n",
      "Compressed size: 599 bytes\n"
     ]
    }
   ],
   "source": [
    "import zlib\n",
    "\n",
    "# Define the original string\n",
    "original_string = text\n",
    "\n",
    "# Compress the string\n",
    "compressed_data = zlib.compress(original_string.encode('utf-8'))\n",
    "\n",
    "# Calculate sizes\n",
    "original_size = len(original_string.encode('utf-8'))\n",
    "compressed_size = len(compressed_data)\n",
    "\n",
    "# Print results\n",
    "print(f\"Original size: {original_size} bytes\")\n",
    "print(f\"Compressed size: {compressed_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just-token-number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "token_string = \"\".join([str(token) for token in tokens])\n",
    "token_size = len(token_string.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "token-rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[220]]), 'attention_mask': tensor([[1]])}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\" \", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50918"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_token_rank(token, preceeding=\" \"):\n",
    "    inputs = tokenizer(preceeding, return_tensors=\"pt\")\n",
    "    logits = model(**inputs).logits\n",
    "    ranked = torch.argsort(logits[0, -1, :], descending=True)\n",
    "    rank = torch.where(ranked == token)[0][0].item()\n",
    "    return rank\n",
    "\n",
    "rank = find_token_rank(tokens[0])\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14990, 1879, 220, 17, 18, 15877]\n",
      "[73567, 25, 7, 0, 7, 1919]\n"
     ]
    }
   ],
   "source": [
    "def find_token_rank(token, preceeding=None):\n",
    "    if preceeding is None:\n",
    "        preceeding = tokenizer(\" \", return_tensors=\"pt\")\n",
    "    if isinstance(preceeding, torch.Tensor):\n",
    "        preceeding = {\n",
    "            \"input_ids\": preceeding,\n",
    "            \"attention_mask\": torch.ones_like(preceeding)\n",
    "        }\n",
    "    if isinstance(preceeding, list):\n",
    "        preceeding = {\n",
    "            \"input_ids\": torch.tensor(preceeding, dtype=torch.long).unsqueeze(0),\n",
    "            \"attention_mask\": torch.ones(len(preceeding), dtype=torch.long).unsqueeze(0)\n",
    "        }\n",
    "    logits = model(**preceeding).logits\n",
    "    ranked = torch.argsort(logits[0, -1, :], descending=True)\n",
    "    rank = torch.where(ranked == token)[0][0].item()\n",
    "    return rank\n",
    "\n",
    "\n",
    "text = \"hello world 23 css\"\n",
    "tokens = tokenizer.encode(text)\n",
    "ranks = [find_token_rank(tokens[0])]\n",
    "for i in range(1, len(tokens)):\n",
    "    preceeding = tokens[:i]\n",
    "    rank = find_token_rank(tokens[i], preceeding)\n",
    "    ranks.append(rank)\n",
    "print(tokens)\n",
    "print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14990, 1879, 220, 17, 18, 15877]\n",
      "hello world 23 css\n"
     ]
    }
   ],
   "source": [
    "def rank_to_token(rank, preceeding=None):\n",
    "    if preceeding is None:\n",
    "        preceeding = tokenizer(\" \", return_tensors=\"pt\")\n",
    "    if isinstance(preceeding, torch.Tensor):\n",
    "        preceeding = {\n",
    "            \"input_ids\": preceeding,\n",
    "            \"attention_mask\": torch.ones_like(preceeding)\n",
    "        }\n",
    "    if isinstance(preceeding, list):\n",
    "        preceeding = {\n",
    "            \"input_ids\": torch.tensor(preceeding, dtype=torch.long).unsqueeze(0),\n",
    "            \"attention_mask\": torch.ones(len(preceeding), dtype=torch.long).unsqueeze(0)\n",
    "        }\n",
    "    logits = model(**preceeding).logits\n",
    "    ranked = torch.argsort(logits[0, -1, :], descending=True)\n",
    "    token = ranked[rank].item()\n",
    "    \n",
    "    return token\n",
    "\n",
    "decoded = []\n",
    "decoded.append(rank_to_token(ranks[0]))\n",
    "for i in range(1, len(ranks)):\n",
    "    preceeding = tokens[:i]\n",
    "    decoded.append(rank_to_token(ranks[i], preceeding))\n",
    "print(decoded)\n",
    "print(tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world 23 css\n",
      "[14990, 1879, 220, 17, 18, 15877]\n"
     ]
    }
   ],
   "source": [
    "def rank_encode(text):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    ranks = [find_token_rank(tokens[0])]\n",
    "    for i in range(1, len(tokens)):\n",
    "        preceeding = tokens[:i]\n",
    "        rank = find_token_rank(tokens[i], preceeding)\n",
    "        ranks.append(rank)\n",
    "    return ranks\n",
    "\n",
    "def rank_decode(ranks, return_tokens=False):\n",
    "    decoded = []\n",
    "    decoded.append(rank_to_token(ranks[0]))\n",
    "    for i in range(1, len(ranks)):\n",
    "        preceeding = decoded\n",
    "        decoded.append(rank_to_token(ranks[i], preceeding))\n",
    "    if return_tokens:\n",
    "        return decoded\n",
    "    return tokenizer.decode(decoded)\n",
    "\n",
    "text = \"hello world 23 css\"\n",
    "ranks = rank_encode(text)\n",
    "decoded = rank_decode(ranks)\n",
    "print(decoded)\n",
    "print(rank_decode(ranks, return_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 1311 bytes\n",
      "zlib-compressed size: 599 bytes\n",
      "Just-token-number size: 1307 bytes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original size: {original_size} bytes\")\n",
    "print(f\"zlib-compressed size: {compressed_size} bytes\")\n",
    "print(f\"Just-token-number size: {token_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
